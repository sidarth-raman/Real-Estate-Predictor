{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "78e19fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4bb11327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p6/bmvt9pvd0vd5t3yfr1yhfh580000gn/T/ipykernel_85846/2212246803.py:2: DtypeWarning: Columns (13,20,53,54,59,60,61,62,63,64,65,66,67,68,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_housing_csv = pd.read_csv('../data/new_housing.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107899\n",
      "17728\n",
      "17087\n",
      "6215\n"
     ]
    }
   ],
   "source": [
    "# housing_csv = pd.read_csv('../data/housing.csv')\n",
    "new_housing_csv = pd.read_csv('../data/new_housing.csv')\n",
    "\n",
    "#Length\n",
    "print(len(new_housing_csv))\n",
    "\n",
    "#Mask Sale Price\n",
    "mask = (new_housing_csv[\"SALE PRICE\"]) > 100000.0\n",
    "new_housing_csv = new_housing_csv[mask]\n",
    "\n",
    "\n",
    "#Mask for Sold after 2010\n",
    "new_housing_csv['SALE DATE'] = pd.to_datetime(new_housing_csv['SALE DATE'])\n",
    "mask = (new_housing_csv[\"SALE DATE\"]).dt.year > 2010\n",
    "new_housing_csv = new_housing_csv[mask]\n",
    "\n",
    "#Length\n",
    "print(len(new_housing_csv))\n",
    "\n",
    "#Only important rows\n",
    "new_housing_csv = new_housing_csv[[\"LAND VAL\", \"PARCEL VAL\", \"IMPROVE VAL\", \"SALE PRICE\", \"SQFT\", \"ROOMS\", \"BEDROOM\", \"BATH\", \"LIVING AREA\", \"GROSS AREA\", \"YEAR\"]]\n",
    "\n",
    "\n",
    "#Remove Nulls\n",
    "mask = new_housing_csv.notnull().all(axis=1)\n",
    "new_housing_csv = new_housing_csv.loc[mask, :]\n",
    "print(len(new_housing_csv))\n",
    "\n",
    "#Remove 0s\n",
    "mask = (new_housing_csv != 0).all(axis=1)\n",
    "new_housing_csv = new_housing_csv.loc[mask, :]\n",
    "\n",
    "\n",
    "#Length\n",
    "print(len(new_housing_csv))\n",
    "\n",
    "\n",
    "housing_data = new_housing_csv[[\"LAND VAL\", \"PARCEL VAL\", \"SQFT\", \"ROOMS\", \"BEDROOM\", \"BATH\", \"LIVING AREA\", \"GROSS AREA\", \"YEAR\"]]\n",
    "housing_label = new_housing_csv[[\"SALE PRICE\"]]\n",
    "\n",
    "\n",
    "\n",
    "# print(new_housing_csv)\n",
    "\n",
    "# housing_data = housing_csv[[\"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"median_income\", \"population\", \"households\"]]\n",
    "# housing_label = housing_csv[[\"median_house_value\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4b3751dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_data\n",
    "Y = housing_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d2fc0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(X, axis=0)\n",
    "sigma = np.std(X, axis=0)\n",
    "X = (X - mu) / sigma\n",
    "\n",
    "mu = np.mean(Y, axis=0)\n",
    "sigma = np.std(Y, axis=0)\n",
    "Y = (Y - mu) / sigma\n",
    "\n",
    "X = pd.DataFrame.to_numpy(X)\n",
    "Y = pd.DataFrame.to_numpy(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7edc0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=128, activation='relu', input_shape=[5])\n",
    "        self.dense2 = tf.keras.layers.Dense(units=32, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=1, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1a6efb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "37f3bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6215\n"
     ]
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "print(len(x))\n",
    "x_train = x[:5000]\n",
    "y_train = y[:5000]\n",
    "x_test = x[5001:6215]\n",
    "y_test = y[5001:6215]\n",
    "# Remove all instances where data is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0493b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.4558\n",
      "Epoch [200/10000], Loss: 0.4349\n",
      "Epoch [300/10000], Loss: 0.4251\n",
      "Epoch [400/10000], Loss: 0.4183\n",
      "Epoch [500/10000], Loss: 0.4129\n",
      "Epoch [600/10000], Loss: 0.4085\n",
      "Epoch [700/10000], Loss: 0.4046\n",
      "Epoch [800/10000], Loss: 0.4011\n",
      "Epoch [900/10000], Loss: 0.3978\n",
      "Epoch [1000/10000], Loss: 0.3947\n",
      "Epoch [1100/10000], Loss: 0.3917\n",
      "Epoch [1200/10000], Loss: 0.3890\n",
      "Epoch [1300/10000], Loss: 0.3860\n",
      "Epoch [1400/10000], Loss: 0.3833\n",
      "Epoch [1500/10000], Loss: 0.3807\n",
      "Epoch [1600/10000], Loss: 0.3782\n",
      "Epoch [1700/10000], Loss: 0.3758\n",
      "Epoch [1800/10000], Loss: 0.3734\n",
      "Epoch [1900/10000], Loss: 0.3710\n",
      "Epoch [2000/10000], Loss: 0.3685\n",
      "Epoch [2100/10000], Loss: 0.3662\n",
      "Epoch [2200/10000], Loss: 0.3639\n",
      "Epoch [2300/10000], Loss: 0.3617\n",
      "Epoch [2400/10000], Loss: 0.3594\n",
      "Epoch [2500/10000], Loss: 0.3571\n",
      "Epoch [2600/10000], Loss: 0.3549\n",
      "Epoch [2700/10000], Loss: 0.3527\n",
      "Epoch [2800/10000], Loss: 0.3504\n",
      "Epoch [2900/10000], Loss: 0.3482\n",
      "Epoch [3000/10000], Loss: 0.3461\n",
      "Epoch [3100/10000], Loss: 0.3440\n",
      "Epoch [3200/10000], Loss: 0.3420\n",
      "Epoch [3300/10000], Loss: 0.3399\n",
      "Epoch [3400/10000], Loss: 0.3379\n",
      "Epoch [3500/10000], Loss: 0.3358\n",
      "Epoch [3600/10000], Loss: 0.3338\n",
      "Epoch [3700/10000], Loss: 0.3318\n",
      "Epoch [3800/10000], Loss: 0.3298\n",
      "Epoch [3900/10000], Loss: 0.3278\n",
      "Epoch [4000/10000], Loss: 0.3258\n",
      "Epoch [4100/10000], Loss: 0.3238\n",
      "Epoch [4200/10000], Loss: 0.3219\n",
      "Epoch [4300/10000], Loss: 0.3200\n",
      "Epoch [4400/10000], Loss: 0.3180\n",
      "Epoch [4500/10000], Loss: 0.3161\n",
      "Epoch [4600/10000], Loss: 0.3142\n",
      "Epoch [4700/10000], Loss: 0.3124\n",
      "Epoch [4800/10000], Loss: 0.3105\n",
      "Epoch [4900/10000], Loss: 0.3086\n",
      "Epoch [5000/10000], Loss: 0.3067\n",
      "Epoch [5100/10000], Loss: 0.3049\n",
      "Epoch [5200/10000], Loss: 0.3030\n",
      "Epoch [5300/10000], Loss: 0.3012\n",
      "Epoch [5400/10000], Loss: 0.2995\n",
      "Epoch [5500/10000], Loss: 0.2977\n",
      "Epoch [5600/10000], Loss: 0.2959\n",
      "Epoch [5700/10000], Loss: 0.2942\n",
      "Epoch [5800/10000], Loss: 0.2924\n",
      "Epoch [5900/10000], Loss: 0.2907\n",
      "Epoch [6000/10000], Loss: 0.2890\n",
      "Epoch [6100/10000], Loss: 0.2873\n",
      "Epoch [6200/10000], Loss: 0.2856\n",
      "Epoch [6300/10000], Loss: 0.2839\n",
      "Epoch [6400/10000], Loss: 0.2822\n",
      "Epoch [6500/10000], Loss: 0.2805\n",
      "Epoch [6600/10000], Loss: 0.2788\n",
      "Epoch [6700/10000], Loss: 0.2771\n",
      "Epoch [6800/10000], Loss: 0.2754\n",
      "Epoch [6900/10000], Loss: 0.2736\n",
      "Epoch [7000/10000], Loss: 0.2720\n",
      "Epoch [7100/10000], Loss: 0.2703\n",
      "Epoch [7200/10000], Loss: 0.2686\n",
      "Epoch [7300/10000], Loss: 0.2669\n",
      "Epoch [7400/10000], Loss: 0.2653\n",
      "Epoch [7500/10000], Loss: 0.2636\n",
      "Epoch [7600/10000], Loss: 0.2620\n",
      "Epoch [7700/10000], Loss: 0.2605\n",
      "Epoch [7800/10000], Loss: 0.2589\n",
      "Epoch [7900/10000], Loss: 0.2573\n",
      "Epoch [8000/10000], Loss: 0.2558\n",
      "Epoch [8100/10000], Loss: 0.2542\n",
      "Epoch [8200/10000], Loss: 0.2527\n",
      "Epoch [8300/10000], Loss: 0.2512\n",
      "Epoch [8400/10000], Loss: 0.2497\n",
      "Epoch [8500/10000], Loss: 0.2482\n",
      "Epoch [8600/10000], Loss: 0.2467\n",
      "Epoch [8700/10000], Loss: 0.2453\n",
      "Epoch [8800/10000], Loss: 0.2439\n",
      "Epoch [8900/10000], Loss: 0.2424\n",
      "Epoch [9000/10000], Loss: 0.2410\n",
      "Epoch [9100/10000], Loss: 0.2396\n",
      "Epoch [9200/10000], Loss: 0.2382\n",
      "Epoch [9300/10000], Loss: 0.2368\n",
      "Epoch [9400/10000], Loss: 0.2354\n",
      "Epoch [9500/10000], Loss: 0.2340\n",
      "Epoch [9600/10000], Loss: 0.2327\n",
      "Epoch [9700/10000], Loss: 0.2313\n",
      "Epoch [9800/10000], Loss: 0.2300\n",
      "Epoch [9900/10000], Loss: 0.2286\n",
      "Epoch [10000/10000], Loss: 0.2273\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x_train)\n",
    "        loss = loss_fn(y_train, y_pred)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d4ada14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.layers[0].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "85b15f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true, sigma, mu, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the predictions given the true labels, based on a threshold value.\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred (np.ndarray): An array of predicted labels.\n",
    "    y_true (np.ndarray): An array of true labels.\n",
    "    threshold (float): The threshold value to use for measuring accuracy.\n",
    "    \n",
    "    Returns:\n",
    "    float: The accuracy of the predictions as a percentage.\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between predicted and true values\n",
    "    \n",
    "    \n",
    "    y_pred = (y_pred * sigma) + mu\n",
    "    y_true = (y_true * sigma) + mu\n",
    "\n",
    "    diff = np.abs(y_pred - y_true)\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = np.mean(diff <= threshold * y_pred)\n",
    "    \n",
    "    # Convert to percentage\n",
    "    acc_pct = acc * 100\n",
    "    \n",
    "    return acc_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1b8fe4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 542774.9 ]\n",
      " [ 762118.25]\n",
      " [ 695176.  ]\n",
      " ...\n",
      " [1013042.9 ]\n",
      " [1320091.  ]\n",
      " [1552182.9 ]], shape=(1214, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 445000.]\n",
      " [ 669000.]\n",
      " [ 657000.]\n",
      " ...\n",
      " [ 810000.]\n",
      " [ 950000.]\n",
      " [1690000.]], shape=(1214, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.49588138385503"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(x_test)\n",
    "loss = loss_fn(y_test, pred)\n",
    "accuracy(pred, y_test, sigma, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "93887275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11458933  0.12156705  0.11700203 ...  0.00323182  0.03688697\n",
      "   0.02554604]\n",
      " [-0.1705997  -0.1211534   0.13011625 ... -0.26055804  0.1319434\n",
      "   0.01007314]\n",
      " [ 0.22833017 -0.24231347  0.00414997 ... -0.17752418 -0.0524627\n",
      "  -0.19856492]\n",
      " ...\n",
      " [-0.18502845  0.04064478  0.1503381  ... -0.12790845 -0.15697888\n",
      "   0.11542995]\n",
      " [-0.17118928 -0.13320403 -0.06279024 ... -0.20220156 -0.08900296\n",
      "   0.28249234]\n",
      " [-0.07024302  0.17712931  0.09056931 ...  0.06407394 -0.1726234\n",
      "   0.12277757]]\n"
     ]
    }
   ],
   "source": [
    "weights, bias = model.layers[0].get_weights()\n",
    "print(weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
