{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "78e19fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e2ddc",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4bb11327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p6/bmvt9pvd0vd5t3yfr1yhfh580000gn/T/ipykernel_88634/3437331789.py:2: DtypeWarning: Columns (13,20,53,54,59,60,61,62,63,64,65,66,67,68,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_housing_csv = pd.read_csv('../data/new_housing.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import Housing Data\n",
    "new_housing_csv = pd.read_csv('../data/new_housing.csv')\n",
    "\n",
    "# Select houses with a Sale Price over $100,000\n",
    "mask = (new_housing_csv[\"SALE PRICE\"]) > 100000.0\n",
    "new_housing_csv = new_housing_csv[mask]\n",
    "\n",
    "# Only select homes sold between 2011 and 2015\n",
    "new_housing_csv['SALE DATE'] = pd.to_datetime(new_housing_csv['SALE DATE'])\n",
    "mask = (new_housing_csv[\"SALE DATE\"]).dt.year > 2011 \n",
    "new_housing_csv = new_housing_csv[mask]\n",
    "mask = (new_housing_csv[\"SALE DATE\"]).dt.year < 2015\n",
    "new_housing_csv = new_housing_csv[mask]\n",
    "\n",
    "\n",
    "# Only select important rows\n",
    "new_housing_csv = new_housing_csv[[\"LAND VAL\", \"PARCEL VAL\", \"IMPROVE VAL\", \"SALE PRICE\", \"SQFT\", \"ROOMS\", \"BEDROOM\", \"BATH\", \"LIVING AREA\", \"GROSS AREA\", \"YEAR\", \"PERCENT GOOD\", \"STORIES\"]]\n",
    "\n",
    "#Remove Nulls and 0s in Data\n",
    "mask = new_housing_csv.notnull().all(axis=1)\n",
    "new_housing_csv = new_housing_csv.loc[mask, :]\n",
    "mask = (new_housing_csv != 0).all(axis=1)\n",
    "new_housing_csv = new_housing_csv.loc[mask, :]\n",
    "\n",
    "# Seperate into Data and Labels\n",
    "housing_data = new_housing_csv[[\"LAND VAL\", \"PARCEL VAL\", \"SQFT\", \"ROOMS\", \"BEDROOM\", \"BATH\", \"LIVING AREA\", \"GROSS AREA\", \"YEAR\",\"PERCENT GOOD\", \"STORIES\"]]\n",
    "housing_label = new_housing_csv[[\"SALE PRICE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d2fc0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_data\n",
    "Y = housing_label\n",
    "\n",
    "def normalize(X):\n",
    "    \"\"\"\n",
    "    Normalizes the data X using the mean and standard deviation.  \n",
    "    \n",
    "    Parameters:\n",
    "    X (np.ndarray): An array of unnormalized data.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The normalized version of the data.\n",
    "    \"\"\"    \n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0)\n",
    "    X = (X - mu) / sigma\n",
    "    return X\n",
    "\n",
    "# Normalize Data\n",
    "X = normalize(X)\n",
    "Y = normalize(Y)\n",
    "\n",
    "# Convert to Numpy Array\n",
    "X = pd.DataFrame.to_numpy(X)\n",
    "Y = pd.DataFrame.to_numpy(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b0905",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7edc0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=128, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=32, activation='relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(units=1, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a6efb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Loss function and Optimizer\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "37f3bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "\n",
    "# Percent of Data used for training\n",
    "train_split = 0.7\n",
    "\n",
    "# Split data into train and test\n",
    "x_train = x[:int(train_split * len(X))]\n",
    "y_train = y[:int(train_split * len(X))]\n",
    "x_test = x[int(train_split * len(X) + 1):(len(X))]\n",
    "y_test = y[int(train_split * len(X) + 1):(len(X))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0493b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.4040\n",
      "Epoch [200/10000], Loss: 0.3726\n",
      "Epoch [300/10000], Loss: 0.3519\n",
      "Epoch [400/10000], Loss: 0.3334\n",
      "Epoch [500/10000], Loss: 0.3162\n",
      "Epoch [600/10000], Loss: 0.3012\n",
      "Epoch [700/10000], Loss: 0.2867\n",
      "Epoch [800/10000], Loss: 0.2729\n",
      "Epoch [900/10000], Loss: 0.2595\n",
      "Epoch [1000/10000], Loss: 0.2470\n",
      "Epoch [1100/10000], Loss: 0.2354\n",
      "Epoch [1200/10000], Loss: 0.2243\n",
      "Epoch [1300/10000], Loss: 0.2139\n",
      "Epoch [1400/10000], Loss: 0.2041\n",
      "Epoch [1500/10000], Loss: 0.1947\n",
      "Epoch [1600/10000], Loss: 0.1855\n",
      "Epoch [1700/10000], Loss: 0.1768\n",
      "Epoch [1800/10000], Loss: 0.1684\n",
      "Epoch [1900/10000], Loss: 0.1605\n",
      "Epoch [2000/10000], Loss: 0.1530\n",
      "Epoch [2100/10000], Loss: 0.1464\n",
      "Epoch [2200/10000], Loss: 0.1459\n",
      "Epoch [2300/10000], Loss: 0.1441\n",
      "Epoch [2400/10000], Loss: 0.1361\n",
      "Epoch [2500/10000], Loss: 0.1372\n",
      "Epoch [2600/10000], Loss: 0.1359\n",
      "Epoch [2700/10000], Loss: 0.1267\n",
      "Epoch [2800/10000], Loss: 0.1212\n",
      "Epoch [2900/10000], Loss: 0.1253\n",
      "Epoch [3000/10000], Loss: 0.1085\n",
      "Epoch [3100/10000], Loss: 0.1283\n",
      "Epoch [3200/10000], Loss: 0.1027\n",
      "Epoch [3300/10000], Loss: 0.1149\n",
      "Epoch [3400/10000], Loss: 0.1028\n",
      "Epoch [3500/10000], Loss: 0.1126\n",
      "Epoch [3600/10000], Loss: 0.0975\n",
      "Epoch [3700/10000], Loss: 0.0980\n",
      "Epoch [3800/10000], Loss: 0.0987\n",
      "Epoch [3900/10000], Loss: 0.0909\n",
      "Epoch [4000/10000], Loss: 0.1037\n",
      "Epoch [4100/10000], Loss: 0.0881\n",
      "Epoch [4200/10000], Loss: 0.1043\n",
      "Epoch [4300/10000], Loss: 0.0826\n",
      "Epoch [4400/10000], Loss: 0.0875\n",
      "Epoch [4500/10000], Loss: 0.0912\n",
      "Epoch [4600/10000], Loss: 0.0779\n",
      "Epoch [4700/10000], Loss: 0.0955\n",
      "Epoch [4800/10000], Loss: 0.0769\n",
      "Epoch [4900/10000], Loss: 0.1004\n",
      "Epoch [5000/10000], Loss: 0.0723\n",
      "Epoch [5100/10000], Loss: 0.0964\n",
      "Epoch [5200/10000], Loss: 0.0713\n",
      "Epoch [5300/10000], Loss: 0.0900\n",
      "Epoch [5400/10000], Loss: 0.0705\n",
      "Epoch [5500/10000], Loss: 0.0763\n",
      "Epoch [5600/10000], Loss: 0.0746\n",
      "Epoch [5700/10000], Loss: 0.0717\n",
      "Epoch [5800/10000], Loss: 0.0773\n",
      "Epoch [5900/10000], Loss: 0.0655\n",
      "Epoch [6000/10000], Loss: 0.0842\n",
      "Epoch [6100/10000], Loss: 0.0639\n",
      "Epoch [6200/10000], Loss: 0.0836\n",
      "Epoch [6300/10000], Loss: 0.0624\n",
      "Epoch [6400/10000], Loss: 0.0749\n",
      "Epoch [6500/10000], Loss: 0.0616\n",
      "Epoch [6600/10000], Loss: 0.0609\n",
      "Epoch [6700/10000], Loss: 0.0772\n",
      "Epoch [6800/10000], Loss: 0.0572\n",
      "Epoch [6900/10000], Loss: 0.0699\n",
      "Epoch [7000/10000], Loss: 0.0652\n",
      "Epoch [7100/10000], Loss: 0.0524\n",
      "Epoch [7200/10000], Loss: 0.0680\n",
      "Epoch [7300/10000], Loss: 0.0606\n",
      "Epoch [7400/10000], Loss: 0.0570\n",
      "Epoch [7500/10000], Loss: 0.0781\n",
      "Epoch [7600/10000], Loss: 0.0508\n",
      "Epoch [7700/10000], Loss: 0.0489\n",
      "Epoch [7800/10000], Loss: 0.0732\n",
      "Epoch [7900/10000], Loss: 0.0528\n",
      "Epoch [8000/10000], Loss: 0.0614\n",
      "Epoch [8100/10000], Loss: 0.0540\n",
      "Epoch [8200/10000], Loss: 0.0463\n",
      "Epoch [8300/10000], Loss: 0.0615\n",
      "Epoch [8400/10000], Loss: 0.0587\n",
      "Epoch [8500/10000], Loss: 0.0476\n",
      "Epoch [8600/10000], Loss: 0.0670\n",
      "Epoch [8700/10000], Loss: 0.0458\n",
      "Epoch [8800/10000], Loss: 0.0516\n",
      "Epoch [8900/10000], Loss: 0.0617\n",
      "Epoch [9000/10000], Loss: 0.0436\n",
      "Epoch [9100/10000], Loss: 0.0479\n",
      "Epoch [9200/10000], Loss: 0.0706\n",
      "Epoch [9300/10000], Loss: 0.0443\n",
      "Epoch [9400/10000], Loss: 0.0410\n",
      "Epoch [9500/10000], Loss: 0.0585\n",
      "Epoch [9600/10000], Loss: 0.0550\n",
      "Epoch [9700/10000], Loss: 0.0398\n",
      "Epoch [9800/10000], Loss: 0.0428\n",
      "Epoch [9900/10000], Loss: 0.0675\n",
      "Epoch [10000/10000], Loss: 0.0484\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x_train)\n",
    "        loss = loss_fn(y_train, y_pred)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "85b15f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true, sigma, mu, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the predictions given the true labels, based on a threshold value.\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred (np.ndarray): An array of predicted labels.\n",
    "    y_true (np.ndarray): An array of true labels.\n",
    "    threshold (float): The threshold value to use for measuring accuracy.\n",
    "    \n",
    "    Returns:\n",
    "    float: The accuracy of the predictions as a percentage.\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between predicted and true values\n",
    "    \n",
    "    \n",
    "    y_pred = (y_pred * sigma) + mu\n",
    "    y_true = (y_true * sigma) + mu\n",
    "\n",
    "    diff = np.abs(y_pred - y_true)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = np.mean(diff <= threshold * y_pred)\n",
    "    \n",
    "    # Convert to percentage\n",
    "    acc_pct = acc * 100\n",
    "    \n",
    "    return acc_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1b8fe4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 58.53174603174603\n",
      "Testing Accuracy: 46.85185185185185\n"
     ]
    }
   ],
   "source": [
    "pred = model(x_train)\n",
    "loss = loss_fn(y_train, pred)\n",
    "print(\"Training Accuracy:\", accuracy(pred, y_train, sigma, mu))\n",
    "\n",
    "pred = model(x_test)\n",
    "loss = loss_fn(y_test, pred)\n",
    "print(\"Testing Accuracy:\", accuracy(pred, y_test, sigma, mu))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
