{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78e19fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25636b52",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4bb11327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p6/bmvt9pvd0vd5t3yfr1yhfh580000gn/T/ipykernel_88634/3437331789.py:2: DtypeWarning: Columns (13,20,53,54,59,60,61,62,63,64,65,66,67,68,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_housing_csv = pd.read_csv('../data/new_housing.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import Housing Data\n",
    "new_housing_csv = pd.read_csv('../data/new_housing.csv')\n",
    "\n",
    "# Select houses with a Sale Price over $100,000\n",
    "mask = (new_housing_csv[\"SALE PRICE\"]) > 100000.0\n",
    "new_housing_csv = new_housing_csv[mask]\n",
    "\n",
    "# Only select homes sold between 2011 and 2015\n",
    "new_housing_csv['SALE DATE'] = pd.to_datetime(new_housing_csv['SALE DATE'])\n",
    "mask = (new_housing_csv[\"SALE DATE\"]).dt.year > 2011 \n",
    "new_housing_csv = new_housing_csv[mask]\n",
    "mask = (new_housing_csv[\"SALE DATE\"]).dt.year < 2015\n",
    "new_housing_csv = new_housing_csv[mask]\n",
    "\n",
    "\n",
    "# Only select important rows\n",
    "new_housing_csv = new_housing_csv[[\"LAND VAL\", \"PARCEL VAL\", \"IMPROVE VAL\", \"SALE PRICE\", \"SQFT\", \"ROOMS\", \"BEDROOM\", \"BATH\", \"LIVING AREA\", \"GROSS AREA\", \"YEAR\", \"PERCENT GOOD\", \"STORIES\"]]\n",
    "\n",
    "#Remove Nulls and 0s in Data\n",
    "mask = new_housing_csv.notnull().all(axis=1)\n",
    "new_housing_csv = new_housing_csv.loc[mask, :]\n",
    "mask = (new_housing_csv != 0).all(axis=1)\n",
    "new_housing_csv = new_housing_csv.loc[mask, :]\n",
    "\n",
    "# Seperate into Data and Labels\n",
    "housing_data = new_housing_csv[[\"LAND VAL\", \"PARCEL VAL\", \"SQFT\", \"ROOMS\", \"BEDROOM\", \"BATH\", \"LIVING AREA\", \"GROSS AREA\", \"YEAR\",\"PERCENT GOOD\", \"STORIES\"]]\n",
    "housing_label = new_housing_csv[[\"SALE PRICE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2fc0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_data\n",
    "Y = housing_label\n",
    "\n",
    "def normalize(X):\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0)\n",
    "    X = (X - mu) / sigma\n",
    "    return X\n",
    "\n",
    "# Normalize Data\n",
    "X = normalize(X)\n",
    "Y = normalize(Y)\n",
    "\n",
    "# Convert to Numpy Array\n",
    "X = pd.DataFrame.to_numpy(X)\n",
    "Y = pd.DataFrame.to_numpy(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780aa88",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7edc0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=128, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=32, activation='relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(units=1, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a6efb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Loss function and Optimizer\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37f3bf64",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([2157,  876, 1439, ..., 3547, 1062, 1021])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [74], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(Y, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      5\u001b[0m data_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[0;32m----> 7\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# x_train = x[:(data_split * len(X))]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# y_train = y[:(data_split * len(X))]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# x_test = x[(data_split * len(X) + 1):(len(X))]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# y_test = y[(data_split * len(X) + 1):(len(X))]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Remove all instances where data is empty\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/dl3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2471\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2469\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m-> 2471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[1;32m   2474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/dl3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2473\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2469\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2472\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2473\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2474\u001b[0m     )\n\u001b[1;32m   2475\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/dl3/lib/python3.9/site-packages/sklearn/utils/__init__.py:361\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/dl3/lib/python3.9/site-packages/sklearn/utils/__init__.py:185\u001b[0m, in \u001b[0;36m_array_indexing\u001b[0;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    184\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:899\u001b[0m, in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    894\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    896\u001b[0m     idx\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    897\u001b[0m   \u001b[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[1;32m    898\u001b[0m   \u001b[38;5;66;03m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[0;32m--> 899\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([2157,  876, 1439, ..., 3547, 1062, 1021])"
     ]
    }
   ],
   "source": [
    "# Convert data to tensors\n",
    "X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "indices_list = indices.tolist()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "\n",
    "# x_train = x[:(data_split * len(X))]\n",
    "# y_train = y[:(data_split * len(X))]\n",
    "# x_test = x[(data_split * len(X) + 1):(len(X))]\n",
    "# y_test = y[(data_split * len(X) + 1):(len(X))]\n",
    "\n",
    "# Remove all instances where data is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0493b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.4116\n",
      "Epoch [200/10000], Loss: 0.3776\n",
      "Epoch [300/10000], Loss: 0.3539\n",
      "Epoch [400/10000], Loss: 0.3332\n",
      "Epoch [500/10000], Loss: 0.3141\n",
      "Epoch [600/10000], Loss: 0.2974\n",
      "Epoch [700/10000], Loss: 0.2824\n",
      "Epoch [800/10000], Loss: 0.2688\n",
      "Epoch [900/10000], Loss: 0.2564\n",
      "Epoch [1000/10000], Loss: 0.2446\n",
      "Epoch [1100/10000], Loss: 0.2336\n",
      "Epoch [1200/10000], Loss: 0.2233\n",
      "Epoch [1300/10000], Loss: 0.2135\n",
      "Epoch [1400/10000], Loss: 0.2045\n",
      "Epoch [1500/10000], Loss: 0.1961\n",
      "Epoch [1600/10000], Loss: 0.1878\n",
      "Epoch [1700/10000], Loss: 0.1801\n",
      "Epoch [1800/10000], Loss: 0.1726\n",
      "Epoch [1900/10000], Loss: 0.1656\n",
      "Epoch [2000/10000], Loss: 0.1590\n",
      "Epoch [2100/10000], Loss: 0.1530\n",
      "Epoch [2200/10000], Loss: 0.1495\n",
      "Epoch [2300/10000], Loss: 0.1471\n",
      "Epoch [2400/10000], Loss: 0.1442\n",
      "Epoch [2500/10000], Loss: 0.1407\n",
      "Epoch [2600/10000], Loss: 0.1365\n",
      "Epoch [2700/10000], Loss: 0.1293\n",
      "Epoch [2800/10000], Loss: 0.1294\n",
      "Epoch [2900/10000], Loss: 0.1255\n",
      "Epoch [3000/10000], Loss: 0.1201\n",
      "Epoch [3100/10000], Loss: 0.1205\n",
      "Epoch [3200/10000], Loss: 0.1363\n",
      "Epoch [3300/10000], Loss: 0.1187\n",
      "Epoch [3400/10000], Loss: 0.1049\n",
      "Epoch [3500/10000], Loss: 0.1353\n",
      "Epoch [3600/10000], Loss: 0.0997\n",
      "Epoch [3700/10000], Loss: 0.1291\n",
      "Epoch [3800/10000], Loss: 0.1021\n",
      "Epoch [3900/10000], Loss: 0.1000\n",
      "Epoch [4000/10000], Loss: 0.1173\n",
      "Epoch [4100/10000], Loss: 0.0994\n",
      "Epoch [4200/10000], Loss: 0.0915\n",
      "Epoch [4300/10000], Loss: 0.1167\n",
      "Epoch [4400/10000], Loss: 0.0968\n",
      "Epoch [4500/10000], Loss: 0.0916\n",
      "Epoch [4600/10000], Loss: 0.0933\n",
      "Epoch [4700/10000], Loss: 0.1006\n",
      "Epoch [4800/10000], Loss: 0.0994\n",
      "Epoch [4900/10000], Loss: 0.0871\n",
      "Epoch [5000/10000], Loss: 0.0850\n",
      "Epoch [5100/10000], Loss: 0.1008\n",
      "Epoch [5200/10000], Loss: 0.0810\n",
      "Epoch [5300/10000], Loss: 0.0877\n",
      "Epoch [5400/10000], Loss: 0.0919\n",
      "Epoch [5500/10000], Loss: 0.0758\n",
      "Epoch [5600/10000], Loss: 0.0974\n",
      "Epoch [5700/10000], Loss: 0.0742\n",
      "Epoch [5800/10000], Loss: 0.0902\n",
      "Epoch [5900/10000], Loss: 0.0739\n",
      "Epoch [6000/10000], Loss: 0.0792\n",
      "Epoch [6100/10000], Loss: 0.0728\n",
      "Epoch [6200/10000], Loss: 0.0762\n",
      "Epoch [6300/10000], Loss: 0.0727\n",
      "Epoch [6400/10000], Loss: 0.0750\n",
      "Epoch [6500/10000], Loss: 0.0712\n",
      "Epoch [6600/10000], Loss: 0.0736\n",
      "Epoch [6700/10000], Loss: 0.0690\n",
      "Epoch [6800/10000], Loss: 0.0737\n",
      "Epoch [6900/10000], Loss: 0.0674\n",
      "Epoch [7000/10000], Loss: 0.0745\n",
      "Epoch [7100/10000], Loss: 0.0606\n",
      "Epoch [7200/10000], Loss: 0.0796\n",
      "Epoch [7300/10000], Loss: 0.0616\n",
      "Epoch [7400/10000], Loss: 0.0724\n",
      "Epoch [7500/10000], Loss: 0.0616\n",
      "Epoch [7600/10000], Loss: 0.0654\n",
      "Epoch [7700/10000], Loss: 0.0651\n",
      "Epoch [7800/10000], Loss: 0.0574\n",
      "Epoch [7900/10000], Loss: 0.0748\n",
      "Epoch [8000/10000], Loss: 0.0544\n",
      "Epoch [8100/10000], Loss: 0.0685\n",
      "Epoch [8200/10000], Loss: 0.0575\n",
      "Epoch [8300/10000], Loss: 0.0577\n",
      "Epoch [8400/10000], Loss: 0.0668\n",
      "Epoch [8500/10000], Loss: 0.0527\n",
      "Epoch [8600/10000], Loss: 0.0643\n",
      "Epoch [8700/10000], Loss: 0.0550\n",
      "Epoch [8800/10000], Loss: 0.0538\n",
      "Epoch [8900/10000], Loss: 0.0610\n",
      "Epoch [9000/10000], Loss: 0.0508\n",
      "Epoch [9100/10000], Loss: 0.0626\n",
      "Epoch [9200/10000], Loss: 0.0487\n",
      "Epoch [9300/10000], Loss: 0.0637\n",
      "Epoch [9400/10000], Loss: 0.0484\n",
      "Epoch [9500/10000], Loss: 0.0606\n",
      "Epoch [9600/10000], Loss: 0.0470\n",
      "Epoch [9700/10000], Loss: 0.0587\n",
      "Epoch [9800/10000], Loss: 0.0466\n",
      "Epoch [9900/10000], Loss: 0.0596\n",
      "Epoch [10000/10000], Loss: 0.0443\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x_train)\n",
    "        loss = loss_fn(y_train, y_pred)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4ada14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'linear_regression_4/dense_16/kernel:0' shape=(11, 128) dtype=float32, numpy=\n",
      "array([[-0.12692076,  0.10856866,  0.04461654, ..., -0.07514493,\n",
      "        -0.0744973 ,  0.01260479],\n",
      "       [-0.14683446, -0.14953981,  0.18442567, ..., -0.20339386,\n",
      "         0.103581  , -0.09291214],\n",
      "       [ 0.1254563 , -0.11002223, -0.05349731, ..., -0.11784876,\n",
      "        -0.03736782, -0.16272876],\n",
      "       ...,\n",
      "       [-0.25042447,  0.25035843,  0.09431099, ...,  0.13657267,\n",
      "        -0.22676115,  0.01360488],\n",
      "       [-0.03390095,  0.18360633,  0.18887787, ...,  0.04897064,\n",
      "         0.2254355 ,  0.05400588],\n",
      "       [-0.15032893, -0.04964776, -0.18149091, ..., -0.06873605,\n",
      "        -0.10752581,  0.31416753]], dtype=float32)>, <tf.Variable 'linear_regression_4/dense_16/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([-3.48075889e-02,  5.71436621e-02, -3.95265818e-02, -1.96170285e-02,\n",
      "       -5.11795841e-02, -3.94228846e-02, -3.07753831e-02,  4.84897792e-02,\n",
      "        5.86357899e-03,  3.40636000e-02,  5.23034669e-02, -5.99466078e-02,\n",
      "        3.69423139e-03, -3.80905753e-04, -6.87918533e-03, -3.56750749e-02,\n",
      "       -4.07607779e-02, -8.37237462e-02, -1.39498673e-02,  8.89548585e-02,\n",
      "       -5.80567718e-02,  3.85879651e-02, -4.11383286e-02,  3.91515298e-03,\n",
      "       -7.87770972e-02,  1.10302441e-01, -6.07760474e-02, -3.26198079e-02,\n",
      "       -1.71874866e-01, -3.75221968e-02, -5.70872314e-02,  4.41656373e-02,\n",
      "        1.08517125e-01,  1.14162624e-01,  1.87393110e-02,  3.28412652e-02,\n",
      "        1.94879789e-02, -3.32492143e-02, -5.76921701e-02, -2.53030229e-02,\n",
      "        5.23201041e-02, -7.14112967e-02, -6.65361956e-02, -7.60313347e-02,\n",
      "        3.06026004e-02,  9.48462784e-02, -9.44465864e-03, -2.84359157e-02,\n",
      "        2.77465880e-02, -2.13879868e-02, -9.13573056e-02, -4.27015759e-02,\n",
      "       -4.41126116e-02, -3.89893353e-02,  6.24866858e-02,  2.35746372e-02,\n",
      "       -1.54596865e-01, -6.47157803e-02,  4.13006963e-03, -6.03527725e-02,\n",
      "       -3.21902595e-02, -9.31946561e-02, -3.25919688e-02,  2.62940489e-02,\n",
      "       -4.46672784e-03, -5.45511097e-02,  2.00717282e-02, -6.86263740e-02,\n",
      "       -1.67335086e-02,  4.26269770e-02, -7.14924261e-02, -7.01505365e-03,\n",
      "        2.44424976e-02,  2.13416964e-02,  3.00572230e-03,  2.20850073e-02,\n",
      "       -3.68572995e-02, -5.95035031e-02, -2.03596652e-02, -1.12867609e-01,\n",
      "       -1.81668419e-02, -1.67568005e-03, -6.19277507e-02, -1.43099856e-03,\n",
      "        6.92218682e-03,  2.48859972e-02,  1.81204418e-03, -3.71785797e-02,\n",
      "        3.18231359e-02,  1.73899624e-02,  7.84305558e-02,  9.81719717e-02,\n",
      "       -1.30357957e-02,  8.47148523e-03,  5.24722040e-03, -7.54591823e-02,\n",
      "       -2.76968256e-02, -7.81451091e-02,  3.02353743e-02,  3.29042748e-02,\n",
      "        5.75542450e-03,  2.50193134e-05, -7.25199236e-03, -4.58300626e-03,\n",
      "       -5.08963577e-02,  7.07254037e-02,  7.72093888e-03,  2.64832424e-03,\n",
      "       -1.57615338e-02,  6.04618341e-02,  4.64387275e-02, -1.32866412e-01,\n",
      "        1.26659736e-01, -1.73924249e-02,  3.04913446e-02, -6.07508458e-02,\n",
      "        6.85904399e-02,  3.27912462e-03,  2.20189355e-02,  4.03844900e-02,\n",
      "        9.37887505e-02, -9.44010988e-02,  9.92040429e-03,  1.10149980e-01,\n",
      "        3.09446100e-02,  7.55784065e-02,  2.75402758e-02, -8.32735561e-04],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85b15f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true, sigma, mu, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the predictions given the true labels, based on a threshold value.\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred (np.ndarray): An array of predicted labels.\n",
    "    y_true (np.ndarray): An array of true labels.\n",
    "    threshold (float): The threshold value to use for measuring accuracy.\n",
    "    \n",
    "    Returns:\n",
    "    float: The accuracy of the predictions as a percentage.\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between predicted and true values\n",
    "    \n",
    "    \n",
    "    y_pred = (y_pred * sigma) + mu\n",
    "    y_true = (y_true * sigma) + mu\n",
    "\n",
    "    diff = np.abs(y_pred - y_true)\n",
    "    print(y_pred)\n",
    "    print(y_true)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = np.mean(diff <= threshold * y_pred)\n",
    "    \n",
    "    # Convert to percentage\n",
    "    acc_pct = acc * 100\n",
    "    \n",
    "    return acc_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b8fe4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[329669.03]\n",
      " [303795.1 ]\n",
      " [285692.34]\n",
      " ...\n",
      " [511830.06]\n",
      " [555258.8 ]\n",
      " [529761.1 ]], shape=(3000, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[309000.  ]\n",
      " [299999.97]\n",
      " [264999.97]\n",
      " ...\n",
      " [460000.  ]\n",
      " [480000.  ]\n",
      " [425000.  ]], shape=(3000, 1), dtype=float32)\n",
      "Training Accuracy: 90.3\n",
      "tf.Tensor(\n",
      "[[ 454911.3 ]\n",
      " [ 731288.94]\n",
      " [ 664541.9 ]\n",
      " [ 464073.12]\n",
      " [1351638.4 ]\n",
      " [ 518510.5 ]\n",
      " [ 509089.  ]\n",
      " [ 636483.8 ]\n",
      " [ 984983.6 ]\n",
      " [ 599913.6 ]\n",
      " [1583548.5 ]\n",
      " [ 644167.6 ]\n",
      " [ 738521.56]\n",
      " [ 550295.9 ]\n",
      " [ 819021.  ]\n",
      " [ 568807.94]\n",
      " [ 843509.6 ]\n",
      " [ 814123.  ]\n",
      " [ 475993.72]\n",
      " [ 477301.2 ]\n",
      " [ 490294.75]\n",
      " [1254651.2 ]\n",
      " [1288440.2 ]\n",
      " [1337536.8 ]\n",
      " [ 508344.1 ]\n",
      " [ 376631.22]\n",
      " [ 484515.3 ]\n",
      " [ 607957.6 ]\n",
      " [ 723235.1 ]\n",
      " [ 747788.5 ]\n",
      " [ 691557.9 ]\n",
      " [ 632108.8 ]\n",
      " [ 478103.3 ]\n",
      " [ 744153.  ]\n",
      " [ 656288.1 ]\n",
      " [ 897131.4 ]\n",
      " [ 684974.25]\n",
      " [ 414631.66]\n",
      " [ 719559.  ]\n",
      " [ 914125.25]\n",
      " [ 906084.9 ]\n",
      " [ 654080.6 ]\n",
      " [ 737468.8 ]\n",
      " [ 662071.  ]\n",
      " [ 619238.7 ]\n",
      " [ 822821.4 ]\n",
      " [ 419660.66]\n",
      " [ 502268.62]\n",
      " [1145174.2 ]\n",
      " [ 679544.94]\n",
      " [ 465323.7 ]\n",
      " [ 487219.25]\n",
      " [ 741775.6 ]\n",
      " [ 915611.7 ]\n",
      " [ 716350.1 ]\n",
      " [ 985604.5 ]\n",
      " [ 652904.94]\n",
      " [ 396528.12]\n",
      " [ 768788.3 ]\n",
      " [ 530373.1 ]\n",
      " [ 593365.8 ]\n",
      " [2114341.5 ]\n",
      " [ 720910.3 ]\n",
      " [ 634542.75]\n",
      " [ 553117.  ]\n",
      " [ 588335.7 ]\n",
      " [1212998.8 ]\n",
      " [ 571078.3 ]\n",
      " [ 650624.6 ]\n",
      " [ 535146.9 ]\n",
      " [ 454011.88]\n",
      " [ 446656.5 ]\n",
      " [ 434776.5 ]\n",
      " [ 724606.8 ]\n",
      " [ 679283.2 ]\n",
      " [1465377.  ]\n",
      " [ 502035.94]\n",
      " [ 667413.25]\n",
      " [ 534156.44]\n",
      " [ 401455.38]\n",
      " [ 641532.  ]\n",
      " [ 684936.44]\n",
      " [ 651571.  ]\n",
      " [ 740816.6 ]\n",
      " [ 550867.94]\n",
      " [ 570680.5 ]\n",
      " [2075483.4 ]\n",
      " [ 930886.25]\n",
      " [ 797674.25]\n",
      " [ 831852.  ]\n",
      " [ 563294.44]\n",
      " [ 748958.56]\n",
      " [ 600434.5 ]\n",
      " [ 595652.8 ]\n",
      " [ 556902.56]\n",
      " [1034505.75]\n",
      " [ 531601.06]\n",
      " [ 949579.94]\n",
      " [ 524256.38]\n",
      " [ 697748.3 ]\n",
      " [ 465100.34]\n",
      " [ 476240.66]\n",
      " [ 603458.1 ]\n",
      " [ 387242.34]\n",
      " [ 882215.9 ]\n",
      " [ 790581.75]\n",
      " [ 605255.44]\n",
      " [ 595688.8 ]\n",
      " [ 464099.94]\n",
      " [ 494127.38]\n",
      " [ 904583.6 ]\n",
      " [ 582257.75]\n",
      " [ 555746.  ]\n",
      " [ 573395.06]\n",
      " [ 966674.4 ]\n",
      " [1312731.  ]\n",
      " [1220075.  ]\n",
      " [ 611151.94]\n",
      " [ 590480.1 ]\n",
      " [ 875994.  ]\n",
      " [ 691957.25]\n",
      " [ 457757.7 ]\n",
      " [ 918185.25]\n",
      " [ 649133.3 ]\n",
      " [ 444380.28]\n",
      " [ 696944.94]\n",
      " [ 975056.6 ]\n",
      " [ 923210.94]\n",
      " [ 451724.2 ]\n",
      " [ 403314.22]\n",
      " [ 635049.44]\n",
      " [ 850611.4 ]\n",
      " [ 705178.8 ]\n",
      " [1007477.  ]\n",
      " [ 913360.5 ]\n",
      " [ 899811.25]\n",
      " [ 630277.1 ]\n",
      " [2954345.8 ]\n",
      " [ 456980.62]\n",
      " [ 640935.7 ]\n",
      " [ 664114.25]\n",
      " [ 401077.62]\n",
      " [ 846197.8 ]\n",
      " [ 886996.4 ]\n",
      " [ 628882.56]\n",
      " [ 816493.7 ]\n",
      " [ 336271.6 ]\n",
      " [ 706252.5 ]\n",
      " [1154989.5 ]\n",
      " [ 244637.47]\n",
      " [ 650186.56]\n",
      " [ 466314.5 ]\n",
      " [ 654647.25]\n",
      " [ 541851.4 ]\n",
      " [1108065.5 ]\n",
      " [ 682184.06]\n",
      " [ 328958.34]\n",
      " [ 701570.6 ]\n",
      " [ 567681.4 ]\n",
      " [1019152.  ]\n",
      " [ 694523.6 ]\n",
      " [ 446358.06]\n",
      " [ 695660.6 ]\n",
      " [ 849318.75]\n",
      " [1665413.5 ]\n",
      " [ 628600.  ]\n",
      " [ 853219.56]\n",
      " [ 258377.78]\n",
      " [ 716644.56]\n",
      " [ 714349.75]\n",
      " [ 534011.  ]\n",
      " [ 805481.6 ]\n",
      " [ 431324.8 ]\n",
      " [ 819269.8 ]\n",
      " [ 525387.4 ]\n",
      " [ 515361.16]\n",
      " [ 666267.5 ]\n",
      " [ 544784.6 ]\n",
      " [ 716974.06]\n",
      " [ 402408.3 ]\n",
      " [ 836195.4 ]\n",
      " [1078372.9 ]\n",
      " [ 293290.84]\n",
      " [1368920.5 ]\n",
      " [1231810.8 ]\n",
      " [ 679465.5 ]\n",
      " [1300967.  ]\n",
      " [1342430.1 ]\n",
      " [ 738121.94]\n",
      " [ 660055.2 ]\n",
      " [ 474552.94]\n",
      " [ 640600.6 ]\n",
      " [ 861098.9 ]\n",
      " [ 743579.2 ]\n",
      " [ 483167.53]\n",
      " [1068416.8 ]\n",
      " [ 495491.5 ]\n",
      " [ 563220.4 ]\n",
      " [ 559529.94]\n",
      " [ 946559.4 ]\n",
      " [ 559346.7 ]\n",
      " [ 847813.75]\n",
      " [ 585015.56]\n",
      " [ 616058.44]\n",
      " [ 739688.94]\n",
      " [ 745335.06]\n",
      " [ 759392.7 ]\n",
      " [ 655655.25]\n",
      " [1340596.  ]\n",
      " [ 719253.1 ]\n",
      " [1004162.3 ]\n",
      " [ 555558.4 ]\n",
      " [ 504248.5 ]\n",
      " [ 639660.06]\n",
      " [ 924367.25]\n",
      " [ 988229.5 ]\n",
      " [1183337.5 ]\n",
      " [ 797855.6 ]\n",
      " [1001042.75]\n",
      " [ 913962.75]\n",
      " [ 856558.2 ]\n",
      " [2583529.5 ]\n",
      " [ 703867.25]\n",
      " [ 519164.12]\n",
      " [ 982853.75]\n",
      " [ 486279.06]\n",
      " [ 513198.88]\n",
      " [ 308728.72]\n",
      " [ 470939.62]\n",
      " [ 425373.8 ]\n",
      " [ 430476.03]\n",
      " [ 660471.06]\n",
      " [1047106.6 ]\n",
      " [ 330479.2 ]\n",
      " [ 831181.75]\n",
      " [ 887283.3 ]\n",
      " [ 554635.3 ]\n",
      " [ 740305.25]\n",
      " [ 798310.44]\n",
      " [ 935293.75]\n",
      " [ 752743.56]\n",
      " [1008808.  ]\n",
      " [ 743106.75]\n",
      " [ 578516.06]\n",
      " [ 375090.1 ]\n",
      " [1379377.5 ]\n",
      " [ 625463.6 ]\n",
      " [ 693046.  ]\n",
      " [ 437724.56]\n",
      " [ 861224.25]\n",
      " [ 622527.4 ]\n",
      " [ 920631.1 ]\n",
      " [ 784585.2 ]\n",
      " [ 578853.4 ]\n",
      " [ 749210.1 ]\n",
      " [ 641895.9 ]\n",
      " [ 532388.  ]\n",
      " [ 928294.9 ]\n",
      " [ 824253.3 ]\n",
      " [ 391451.3 ]\n",
      " [ 946260.1 ]\n",
      " [ 663334.2 ]\n",
      " [ 887352.3 ]\n",
      " [ 926747.44]\n",
      " [ 683701.9 ]\n",
      " [ 815300.7 ]\n",
      " [ 663280.56]\n",
      " [ 991167.75]\n",
      " [ 853068.7 ]\n",
      " [ 511687.2 ]\n",
      " [ 652819.5 ]\n",
      " [ 517621.84]\n",
      " [ 694617.56]\n",
      " [ 662073.06]\n",
      " [ 392632.03]\n",
      " [1220021.4 ]\n",
      " [1373017.9 ]\n",
      " [ 528945.25]\n",
      " [ 403229.75]\n",
      " [ 634140.75]\n",
      " [ 472893.62]\n",
      " [ 710662.25]\n",
      " [1047625.94]\n",
      " [ 957658.1 ]\n",
      " [ 669342.7 ]\n",
      " [ 753031.4 ]\n",
      " [ 431079.88]\n",
      " [ 535706.25]\n",
      " [ 779194.7 ]\n",
      " [ 310010.53]\n",
      " [ 751072.6 ]\n",
      " [1179026.9 ]\n",
      " [ 533478.5 ]\n",
      " [ 435623.1 ]\n",
      " [1036501.25]\n",
      " [ 563781.5 ]\n",
      " [ 470481.  ]\n",
      " [ 901731.75]\n",
      " [ 767378.06]\n",
      " [ 920863.9 ]\n",
      " [ 577149.06]\n",
      " [ 966864.4 ]\n",
      " [ 627020.4 ]\n",
      " [1082994.8 ]\n",
      " [ 604602.8 ]\n",
      " [ 550037.1 ]\n",
      " [ 735756.9 ]\n",
      " [ 670844.7 ]\n",
      " [ 732490.75]\n",
      " [1487283.5 ]\n",
      " [ 470369.  ]\n",
      " [ 529579.9 ]\n",
      " [ 779135.25]\n",
      " [ 688651.7 ]\n",
      " [ 400288.44]\n",
      " [1000253.25]\n",
      " [ 655781.75]\n",
      " [ 408628.7 ]\n",
      " [1021325.44]\n",
      " [ 459304.75]\n",
      " [ 474737.2 ]\n",
      " [ 673767.  ]\n",
      " [ 549246.6 ]\n",
      " [ 765237.94]\n",
      " [ 526924.75]\n",
      " [ 826537.25]\n",
      " [ 415190.  ]\n",
      " [1341224.4 ]\n",
      " [1194432.2 ]\n",
      " [ 630537.5 ]\n",
      " [ 658079.1 ]\n",
      " [ 758002.6 ]\n",
      " [ 663303.9 ]\n",
      " [ 481846.34]\n",
      " [ 630938.2 ]\n",
      " [ 754772.3 ]\n",
      " [ 760628.7 ]\n",
      " [ 480673.3 ]\n",
      " [ 400467.78]\n",
      " [ 717507.8 ]\n",
      " [ 645204.06]\n",
      " [2690532.  ]\n",
      " [1597432.4 ]\n",
      " [1065849.8 ]\n",
      " [3020419.2 ]\n",
      " [ 970540.25]\n",
      " [ 637664.75]\n",
      " [ 959397.25]\n",
      " [ 478430.5 ]\n",
      " [1578991.1 ]\n",
      " [ 783841.25]\n",
      " [ 701650.06]\n",
      " [ 464717.25]\n",
      " [ 918617.1 ]\n",
      " [ 672507.  ]\n",
      " [1074370.2 ]\n",
      " [ 874249.4 ]\n",
      " [1416013.  ]\n",
      " [ 815919.9 ]\n",
      " [ 520869.94]\n",
      " [ 938837.25]\n",
      " [ 710994.94]\n",
      " [1105632.5 ]\n",
      " [ 625560.1 ]\n",
      " [ 655293.1 ]\n",
      " [ 582717.4 ]\n",
      " [ 590754.06]\n",
      " [ 586594.6 ]\n",
      " [ 452920.66]\n",
      " [ 545275.7 ]\n",
      " [ 941044.7 ]\n",
      " [ 710635.1 ]\n",
      " [ 718476.6 ]\n",
      " [ 596447.7 ]\n",
      " [ 585030.3 ]\n",
      " [ 640530.5 ]\n",
      " [ 702514.25]\n",
      " [ 809021.56]\n",
      " [ 824909.9 ]\n",
      " [ 599730.56]\n",
      " [ 502486.56]\n",
      " [ 818092.44]\n",
      " [ 737324.2 ]\n",
      " [ 606884.8 ]\n",
      " [ 649785.4 ]\n",
      " [ 501867.2 ]\n",
      " [1039327.3 ]\n",
      " [ 721739.06]\n",
      " [1053830.9 ]\n",
      " [ 450905.38]\n",
      " [ 495211.2 ]\n",
      " [ 881885.8 ]\n",
      " [ 788388.2 ]\n",
      " [1070133.1 ]\n",
      " [ 572798.9 ]\n",
      " [ 664833.75]\n",
      " [ 500602.  ]\n",
      " [1031530.9 ]\n",
      " [ 666796.6 ]\n",
      " [ 467919.34]\n",
      " [ 864784.2 ]\n",
      " [ 683221.  ]\n",
      " [ 885838.94]\n",
      " [ 760466.7 ]\n",
      " [ 336615.6 ]\n",
      " [ 598560.4 ]\n",
      " [ 493225.16]\n",
      " [ 376233.88]\n",
      " [ 311267.3 ]\n",
      " [1535136.  ]\n",
      " [ 873046.5 ]\n",
      " [ 699705.7 ]\n",
      " [ 457702.22]\n",
      " [1228213.5 ]\n",
      " [ 502728.5 ]\n",
      " [ 524239.94]\n",
      " [ 571553.44]\n",
      " [ 788446.75]\n",
      " [ 670648.9 ]\n",
      " [ 604504.75]\n",
      " [ 486320.88]\n",
      " [ 600001.06]\n",
      " [ 772727.06]\n",
      " [ 595359.2 ]\n",
      " [ 553265.75]\n",
      " [ 319604.8 ]\n",
      " [ 942563.1 ]\n",
      " [ 591920.5 ]\n",
      " [ 793404.7 ]\n",
      " [ 493244.66]\n",
      " [ 452847.  ]\n",
      " [ 645834.44]\n",
      " [ 520052.94]\n",
      " [ 657173.4 ]\n",
      " [ 651624.56]\n",
      " [ 426260.75]\n",
      " [ 562734.2 ]\n",
      " [ 887556.75]\n",
      " [ 379253.97]\n",
      " [ 461733.44]\n",
      " [ 735734.7 ]\n",
      " [ 765818.9 ]\n",
      " [ 832311.6 ]\n",
      " [ 637243.56]\n",
      " [ 509633.56]\n",
      " [ 645622.3 ]\n",
      " [ 505767.2 ]\n",
      " [ 732279.7 ]\n",
      " [ 502642.94]\n",
      " [ 740944.9 ]\n",
      " [ 777556.44]\n",
      " [ 641288.  ]\n",
      " [1098296.6 ]\n",
      " [ 540123.6 ]\n",
      " [ 762052.6 ]\n",
      " [ 624171.5 ]\n",
      " [ 538257.94]\n",
      " [ 528491.44]\n",
      " [ 583364.1 ]\n",
      " [ 771688.44]\n",
      " [ 447579.75]\n",
      " [1177005.8 ]\n",
      " [ 823671.1 ]\n",
      " [1201320.5 ]\n",
      " [ 985590.25]\n",
      " [ 570639.94]\n",
      " [ 607808.7 ]\n",
      " [ 905847.25]\n",
      " [ 896217.7 ]\n",
      " [ 450481.2 ]\n",
      " [ 588081.7 ]\n",
      " [ 705847.  ]\n",
      " [ 762697.75]\n",
      " [ 452929.7 ]\n",
      " [ 967602.2 ]\n",
      " [ 905820.25]\n",
      " [ 489757.12]\n",
      " [ 431157.94]\n",
      " [ 692998.9 ]\n",
      " [ 664420.1 ]\n",
      " [ 704622.4 ]\n",
      " [ 408873.  ]\n",
      " [ 718529.8 ]\n",
      " [ 365722.53]\n",
      " [1339249.  ]\n",
      " [ 748430.6 ]\n",
      " [ 399392.38]\n",
      " [ 641370.9 ]\n",
      " [ 621082.25]\n",
      " [ 399836.78]\n",
      " [ 420181.5 ]\n",
      " [ 623579.9 ]\n",
      " [ 576481.5 ]\n",
      " [1109889.  ]\n",
      " [ 835510.4 ]\n",
      " [ 560164.75]\n",
      " [1047318.  ]\n",
      " [ 622352.9 ]\n",
      " [ 762430.94]\n",
      " [ 876759.1 ]\n",
      " [ 787177.2 ]\n",
      " [ 851638.25]\n",
      " [ 818090.2 ]\n",
      " [ 613316.06]\n",
      " [ 416058.44]\n",
      " [ 861485.5 ]\n",
      " [ 951739.7 ]\n",
      " [2011499.1 ]\n",
      " [ 639976.7 ]\n",
      " [ 660437.3 ]\n",
      " [ 759030.25]\n",
      " [ 633963.1 ]\n",
      " [3083801.  ]\n",
      " [ 638655.4 ]\n",
      " [ 859253.75]\n",
      " [ 635867.8 ]\n",
      " [ 636087.7 ]\n",
      " [ 985178.  ]\n",
      " [ 844836.5 ]\n",
      " [ 825901.9 ]\n",
      " [ 617238.  ]\n",
      " [ 679110.94]\n",
      " [ 462672.06]\n",
      " [ 495991.25]\n",
      " [ 852749.94]\n",
      " [ 561196.75]\n",
      " [ 728040.  ]\n",
      " [1262847.8 ]\n",
      " [2450171.2 ]\n",
      " [ 587994.56]\n",
      " [1284913.  ]\n",
      " [1564531.  ]\n",
      " [ 452218.75]\n",
      " [ 962321.06]\n",
      " [ 505724.38]\n",
      " [ 710172.06]\n",
      " [ 977682.75]\n",
      " [1215595.2 ]\n",
      " [ 643938.44]\n",
      " [ 514796.  ]\n",
      " [ 926465.25]\n",
      " [ 638333.  ]\n",
      " [ 999310.1 ]\n",
      " [ 566050.1 ]\n",
      " [ 640433.4 ]\n",
      " [ 533519.3 ]\n",
      " [ 776233.  ]\n",
      " [ 633660.3 ]\n",
      " [ 662502.6 ]\n",
      " [ 816505.7 ]\n",
      " [ 916270.4 ]\n",
      " [ 600599.06]\n",
      " [1134475.4 ]\n",
      " [ 957603.6 ]\n",
      " [ 472754.25]\n",
      " [ 334300.62]\n",
      " [ 386983.94]\n",
      " [ 765186.9 ]\n",
      " [ 663391.  ]\n",
      " [1470805.2 ]\n",
      " [1490336.5 ]\n",
      " [1423642.  ]\n",
      " [ 761812.3 ]\n",
      " [ 597967.9 ]\n",
      " [1000659.6 ]\n",
      " [ 722932.4 ]\n",
      " [ 958527.7 ]\n",
      " [ 572982.9 ]\n",
      " [ 535839.6 ]\n",
      " [ 690989.06]\n",
      " [ 476065.03]\n",
      " [ 676652.25]\n",
      " [ 479932.25]\n",
      " [ 918880.5 ]\n",
      " [1160257.  ]\n",
      " [ 653536.  ]\n",
      " [ 767437.4 ]\n",
      " [ 454458.2 ]\n",
      " [ 868352.06]\n",
      " [ 456331.06]\n",
      " [ 970915.1 ]\n",
      " [ 509471.25]\n",
      " [ 456833.5 ]\n",
      " [ 546422.56]\n",
      " [ 422993.3 ]\n",
      " [ 858135.2 ]\n",
      " [ 793111.44]\n",
      " [2799235.8 ]\n",
      " [ 894512.06]\n",
      " [ 533124.7 ]\n",
      " [ 762292.9 ]\n",
      " [ 431674.25]\n",
      " [ 667241.56]\n",
      " [5348209.  ]\n",
      " [ 683954.1 ]\n",
      " [ 799210.5 ]\n",
      " [1002404.5 ]\n",
      " [ 944615.75]\n",
      " [ 886850.06]\n",
      " [ 909798.25]], shape=(600, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 550000.  ]\n",
      " [ 580000.  ]\n",
      " [ 615000.  ]\n",
      " [ 314000.  ]\n",
      " [1360000.  ]\n",
      " [ 385000.  ]\n",
      " [ 415000.  ]\n",
      " [ 465000.  ]\n",
      " [ 750000.  ]\n",
      " [ 615000.  ]\n",
      " [1500000.  ]\n",
      " [ 650000.  ]\n",
      " [ 728000.  ]\n",
      " [ 561000.  ]\n",
      " [ 735000.  ]\n",
      " [ 510000.  ]\n",
      " [ 805000.  ]\n",
      " [ 755000.  ]\n",
      " [ 476500.  ]\n",
      " [ 375000.  ]\n",
      " [ 274175.  ]\n",
      " [1200000.  ]\n",
      " [1200000.  ]\n",
      " [1200000.  ]\n",
      " [ 415000.  ]\n",
      " [ 295000.  ]\n",
      " [ 433000.  ]\n",
      " [ 411154.  ]\n",
      " [ 680000.  ]\n",
      " [ 640000.  ]\n",
      " [ 710000.  ]\n",
      " [ 675000.  ]\n",
      " [ 344999.97]\n",
      " [ 624500.  ]\n",
      " [ 575000.  ]\n",
      " [ 840000.  ]\n",
      " [ 410000.  ]\n",
      " [ 344999.97]\n",
      " [ 585000.  ]\n",
      " [ 746500.  ]\n",
      " [ 780000.  ]\n",
      " [ 590000.  ]\n",
      " [ 700000.  ]\n",
      " [ 730000.  ]\n",
      " [ 445000.  ]\n",
      " [ 669000.  ]\n",
      " [ 287000.  ]\n",
      " [ 419900.  ]\n",
      " [1050000.  ]\n",
      " [ 797000.  ]\n",
      " [ 495000.  ]\n",
      " [ 329000.  ]\n",
      " [ 700000.  ]\n",
      " [ 850000.  ]\n",
      " [ 755000.  ]\n",
      " [1090000.  ]\n",
      " [ 601500.  ]\n",
      " [ 315000.  ]\n",
      " [ 758000.  ]\n",
      " [ 555000.  ]\n",
      " [ 535000.  ]\n",
      " [ 340000.  ]\n",
      " [ 540000.  ]\n",
      " [ 544375.  ]\n",
      " [ 512000.  ]\n",
      " [ 470000.  ]\n",
      " [1280000.  ]\n",
      " [ 550000.  ]\n",
      " [ 597000.  ]\n",
      " [ 455000.  ]\n",
      " [ 317000.  ]\n",
      " [ 418000.  ]\n",
      " [ 375000.  ]\n",
      " [ 712000.  ]\n",
      " [ 650000.  ]\n",
      " [1230000.  ]\n",
      " [ 205000.  ]\n",
      " [ 550000.  ]\n",
      " [ 381000.  ]\n",
      " [ 375000.  ]\n",
      " [ 550000.  ]\n",
      " [ 605000.  ]\n",
      " [ 538000.  ]\n",
      " [ 785000.  ]\n",
      " [ 510000.  ]\n",
      " [ 535000.  ]\n",
      " [2100000.  ]\n",
      " [ 900000.  ]\n",
      " [ 730000.  ]\n",
      " [ 469000.  ]\n",
      " [ 454000.  ]\n",
      " [ 605000.  ]\n",
      " [ 591500.  ]\n",
      " [ 651601.  ]\n",
      " [ 475000.  ]\n",
      " [1003000.  ]\n",
      " [ 510000.  ]\n",
      " [ 925000.  ]\n",
      " [ 588000.  ]\n",
      " [ 490000.  ]\n",
      " [ 461000.  ]\n",
      " [ 420000.  ]\n",
      " [ 585000.  ]\n",
      " [ 420000.  ]\n",
      " [ 793000.  ]\n",
      " [ 750000.  ]\n",
      " [ 528800.  ]\n",
      " [ 475000.  ]\n",
      " [ 419000.  ]\n",
      " [ 350000.  ]\n",
      " [ 751000.  ]\n",
      " [ 350000.  ]\n",
      " [ 520000.  ]\n",
      " [ 350000.  ]\n",
      " [ 930000.  ]\n",
      " [1125000.  ]\n",
      " [1295000.  ]\n",
      " [ 680000.  ]\n",
      " [ 520000.  ]\n",
      " [ 754900.  ]\n",
      " [ 655000.  ]\n",
      " [ 533000.  ]\n",
      " [ 830000.  ]\n",
      " [ 529000.  ]\n",
      " [ 375000.  ]\n",
      " [ 645000.  ]\n",
      " [ 900000.  ]\n",
      " [ 855000.  ]\n",
      " [ 278000.  ]\n",
      " [ 389900.  ]\n",
      " [ 442500.  ]\n",
      " [ 764000.  ]\n",
      " [ 575000.  ]\n",
      " [ 750000.  ]\n",
      " [ 830000.  ]\n",
      " [ 705000.  ]\n",
      " [ 615000.  ]\n",
      " [3093633.  ]\n",
      " [ 420000.  ]\n",
      " [ 537000.  ]\n",
      " [ 732500.  ]\n",
      " [ 356000.  ]\n",
      " [ 849000.  ]\n",
      " [ 773500.  ]\n",
      " [ 680000.  ]\n",
      " [ 832000.  ]\n",
      " [ 299999.97]\n",
      " [ 569500.  ]\n",
      " [1136000.  ]\n",
      " [ 174999.97]\n",
      " [ 589000.  ]\n",
      " [ 385000.  ]\n",
      " [ 610000.  ]\n",
      " [ 569000.  ]\n",
      " [1180000.  ]\n",
      " [ 670000.  ]\n",
      " [ 275000.  ]\n",
      " [ 620000.  ]\n",
      " [ 520000.  ]\n",
      " [ 960000.  ]\n",
      " [ 652625.  ]\n",
      " [ 360000.  ]\n",
      " [ 615000.  ]\n",
      " [ 825000.  ]\n",
      " [ 580000.  ]\n",
      " [ 625000.  ]\n",
      " [ 910000.  ]\n",
      " [ 249999.97]\n",
      " [ 679500.  ]\n",
      " [ 715000.  ]\n",
      " [ 342147.97]\n",
      " [ 743000.  ]\n",
      " [ 365000.  ]\n",
      " [ 640000.  ]\n",
      " [ 533000.  ]\n",
      " [ 530000.  ]\n",
      " [ 692500.  ]\n",
      " [ 600000.  ]\n",
      " [ 612500.  ]\n",
      " [ 450000.  ]\n",
      " [ 653000.  ]\n",
      " [1180000.  ]\n",
      " [ 263000.  ]\n",
      " [1001000.  ]\n",
      " [1250000.  ]\n",
      " [ 599900.  ]\n",
      " [1200000.  ]\n",
      " [1250000.  ]\n",
      " [ 500000.  ]\n",
      " [ 552500.  ]\n",
      " [ 508000.  ]\n",
      " [ 354999.97]\n",
      " [ 760000.  ]\n",
      " [ 730000.  ]\n",
      " [ 500000.  ]\n",
      " [ 865000.  ]\n",
      " [ 390000.  ]\n",
      " [ 370000.  ]\n",
      " [ 398400.  ]\n",
      " [ 850000.  ]\n",
      " [ 490000.  ]\n",
      " [ 800000.  ]\n",
      " [ 550500.  ]\n",
      " [ 525000.  ]\n",
      " [1150000.  ]\n",
      " [ 715000.  ]\n",
      " [ 865000.  ]\n",
      " [ 505000.  ]\n",
      " [1200000.  ]\n",
      " [ 525000.  ]\n",
      " [ 951000.  ]\n",
      " [ 480000.  ]\n",
      " [ 529000.  ]\n",
      " [ 543000.  ]\n",
      " [ 866000.  ]\n",
      " [ 940000.  ]\n",
      " [1050000.  ]\n",
      " [ 789000.  ]\n",
      " [ 990000.  ]\n",
      " [ 870000.  ]\n",
      " [ 615000.  ]\n",
      " [2400000.  ]\n",
      " [ 620000.  ]\n",
      " [ 400000.  ]\n",
      " [1100000.  ]\n",
      " [ 460000.  ]\n",
      " [ 410000.  ]\n",
      " [ 244999.97]\n",
      " [ 390000.  ]\n",
      " [ 272000.  ]\n",
      " [ 394000.  ]\n",
      " [ 600000.  ]\n",
      " [ 815000.  ]\n",
      " [ 249999.97]\n",
      " [ 780000.  ]\n",
      " [ 725111.  ]\n",
      " [ 500000.  ]\n",
      " [ 615000.  ]\n",
      " [ 450000.  ]\n",
      " [ 775000.  ]\n",
      " [ 640000.  ]\n",
      " [ 770000.  ]\n",
      " [ 652000.  ]\n",
      " [ 555000.  ]\n",
      " [ 270000.  ]\n",
      " [1380000.  ]\n",
      " [ 600000.  ]\n",
      " [ 780000.  ]\n",
      " [ 330000.  ]\n",
      " [ 800000.  ]\n",
      " [ 530000.  ]\n",
      " [ 841000.  ]\n",
      " [ 850000.  ]\n",
      " [ 430000.  ]\n",
      " [ 755000.  ]\n",
      " [ 540000.  ]\n",
      " [ 450000.  ]\n",
      " [ 880000.  ]\n",
      " [ 785000.  ]\n",
      " [ 180000.  ]\n",
      " [ 945000.  ]\n",
      " [ 620000.  ]\n",
      " [ 720000.  ]\n",
      " [ 960000.  ]\n",
      " [ 535000.  ]\n",
      " [ 660500.  ]\n",
      " [ 430000.  ]\n",
      " [1070000.  ]\n",
      " [ 515000.  ]\n",
      " [ 465000.  ]\n",
      " [ 380000.  ]\n",
      " [ 380000.  ]\n",
      " [ 700000.  ]\n",
      " [ 549900.  ]\n",
      " [ 393000.  ]\n",
      " [1260000.  ]\n",
      " [1300000.  ]\n",
      " [ 492000.  ]\n",
      " [ 255000.  ]\n",
      " [ 524000.  ]\n",
      " [ 381000.  ]\n",
      " [ 699000.  ]\n",
      " [ 875000.  ]\n",
      " [ 635000.  ]\n",
      " [ 624500.  ]\n",
      " [ 670000.  ]\n",
      " [ 291250.  ]\n",
      " [ 390000.  ]\n",
      " [ 685000.  ]\n",
      " [ 205999.97]\n",
      " [ 715000.  ]\n",
      " [1175000.  ]\n",
      " [ 454000.  ]\n",
      " [ 404900.  ]\n",
      " [ 900000.  ]\n",
      " [ 365000.  ]\n",
      " [ 452000.  ]\n",
      " [ 810000.  ]\n",
      " [ 775000.  ]\n",
      " [1013880.  ]\n",
      " [ 600000.  ]\n",
      " [ 920000.  ]\n",
      " [ 650000.  ]\n",
      " [ 989000.  ]\n",
      " [ 597500.  ]\n",
      " [ 488000.  ]\n",
      " [ 740000.  ]\n",
      " [ 525000.  ]\n",
      " [ 630000.  ]\n",
      " [1395000.  ]\n",
      " [ 459000.  ]\n",
      " [ 535000.  ]\n",
      " [ 770000.  ]\n",
      " [ 630000.  ]\n",
      " [ 395625.  ]\n",
      " [ 780000.  ]\n",
      " [ 606500.  ]\n",
      " [ 264000.  ]\n",
      " [ 955000.  ]\n",
      " [ 415000.  ]\n",
      " [ 406000.  ]\n",
      " [ 700000.  ]\n",
      " [ 585000.  ]\n",
      " [ 800000.  ]\n",
      " [ 490000.  ]\n",
      " [ 632800.  ]\n",
      " [ 372450.  ]\n",
      " [1335000.  ]\n",
      " [1055000.  ]\n",
      " [ 520000.  ]\n",
      " [ 540000.  ]\n",
      " [ 500000.  ]\n",
      " [ 515000.  ]\n",
      " [ 528000.  ]\n",
      " [ 560000.  ]\n",
      " [ 665000.  ]\n",
      " [ 730000.  ]\n",
      " [ 378499.97]\n",
      " [ 415000.  ]\n",
      " [ 640000.  ]\n",
      " [ 630000.  ]\n",
      " [2679046.  ]\n",
      " [1400000.  ]\n",
      " [ 950000.  ]\n",
      " [3093633.  ]\n",
      " [ 915000.  ]\n",
      " [ 588000.  ]\n",
      " [ 962500.  ]\n",
      " [ 540000.  ]\n",
      " [1500000.  ]\n",
      " [ 729000.  ]\n",
      " [ 619000.  ]\n",
      " [ 460000.  ]\n",
      " [ 865000.  ]\n",
      " [ 595000.  ]\n",
      " [1050000.  ]\n",
      " [ 755000.  ]\n",
      " [1290000.  ]\n",
      " [ 595000.  ]\n",
      " [ 485000.  ]\n",
      " [ 836000.  ]\n",
      " [ 576000.  ]\n",
      " [ 952000.  ]\n",
      " [ 640000.  ]\n",
      " [ 663500.  ]\n",
      " [ 525000.  ]\n",
      " [ 547500.  ]\n",
      " [ 327333.  ]\n",
      " [ 375000.  ]\n",
      " [ 480000.  ]\n",
      " [ 585000.  ]\n",
      " [ 675000.  ]\n",
      " [ 735000.  ]\n",
      " [ 599000.  ]\n",
      " [ 630000.  ]\n",
      " [ 642000.  ]\n",
      " [ 579000.  ]\n",
      " [ 544000.  ]\n",
      " [ 782000.  ]\n",
      " [ 499000.  ]\n",
      " [ 447000.  ]\n",
      " [ 740000.  ]\n",
      " [ 640000.  ]\n",
      " [ 400000.  ]\n",
      " [ 530000.  ]\n",
      " [ 380000.  ]\n",
      " [ 724000.  ]\n",
      " [ 850000.  ]\n",
      " [1310000.  ]\n",
      " [ 330000.  ]\n",
      " [ 412500.  ]\n",
      " [ 850000.  ]\n",
      " [ 585250.  ]\n",
      " [1100000.  ]\n",
      " [ 441000.  ]\n",
      " [ 555000.  ]\n",
      " [ 659900.  ]\n",
      " [1025000.  ]\n",
      " [ 540000.  ]\n",
      " [ 450000.  ]\n",
      " [ 840000.  ]\n",
      " [ 574000.  ]\n",
      " [ 855000.  ]\n",
      " [ 850000.  ]\n",
      " [ 209999.97]\n",
      " [ 491000.  ]\n",
      " [ 449000.  ]\n",
      " [ 295999.97]\n",
      " [ 185000.  ]\n",
      " [1470000.  ]\n",
      " [ 700000.  ]\n",
      " [ 565000.  ]\n",
      " [ 546750.  ]\n",
      " [1000000.  ]\n",
      " [ 279999.97]\n",
      " [ 510000.  ]\n",
      " [ 580000.  ]\n",
      " [ 720000.  ]\n",
      " [ 605000.  ]\n",
      " [ 560000.  ]\n",
      " [ 324000.  ]\n",
      " [ 540000.  ]\n",
      " [ 485000.  ]\n",
      " [ 354999.97]\n",
      " [ 535000.  ]\n",
      " [ 279999.97]\n",
      " [1025000.  ]\n",
      " [ 489000.  ]\n",
      " [ 879000.  ]\n",
      " [ 331269.97]\n",
      " [ 408000.  ]\n",
      " [ 590000.  ]\n",
      " [ 490000.  ]\n",
      " [ 560000.  ]\n",
      " [ 554900.  ]\n",
      " [ 264999.97]\n",
      " [ 520000.  ]\n",
      " [ 520000.  ]\n",
      " [ 450000.  ]\n",
      " [ 249999.97]\n",
      " [ 680000.  ]\n",
      " [ 630000.  ]\n",
      " [ 818000.  ]\n",
      " [ 400000.  ]\n",
      " [ 337499.97]\n",
      " [ 505000.  ]\n",
      " [ 425000.  ]\n",
      " [ 575000.  ]\n",
      " [ 387750.  ]\n",
      " [ 625000.  ]\n",
      " [ 668000.  ]\n",
      " [ 615000.  ]\n",
      " [1000000.  ]\n",
      " [ 504000.  ]\n",
      " [ 510000.  ]\n",
      " [ 515000.  ]\n",
      " [ 455000.  ]\n",
      " [ 455000.  ]\n",
      " [ 183108.  ]\n",
      " [ 685000.  ]\n",
      " [ 486575.  ]\n",
      " [ 940000.  ]\n",
      " [ 735000.  ]\n",
      " [ 961000.  ]\n",
      " [ 815000.  ]\n",
      " [ 395100.  ]\n",
      " [ 580000.  ]\n",
      " [ 820000.  ]\n",
      " [ 759000.  ]\n",
      " [ 436500.  ]\n",
      " [ 505000.  ]\n",
      " [ 595000.  ]\n",
      " [ 670000.  ]\n",
      " [ 365000.  ]\n",
      " [ 850000.  ]\n",
      " [ 708000.  ]\n",
      " [ 381259.  ]\n",
      " [ 299999.97]\n",
      " [ 745000.  ]\n",
      " [ 500000.  ]\n",
      " [ 630000.  ]\n",
      " [ 329000.  ]\n",
      " [ 725000.  ]\n",
      " [ 284999.97]\n",
      " [1075000.  ]\n",
      " [ 739000.  ]\n",
      " [ 236000.  ]\n",
      " [ 575000.  ]\n",
      " [ 501500.  ]\n",
      " [ 264999.97]\n",
      " [ 540000.  ]\n",
      " [ 500000.  ]\n",
      " [ 500000.  ]\n",
      " [1035000.  ]\n",
      " [ 725000.  ]\n",
      " [ 569000.  ]\n",
      " [1025000.  ]\n",
      " [ 562000.  ]\n",
      " [ 875000.  ]\n",
      " [ 770000.  ]\n",
      " [ 670000.  ]\n",
      " [ 820000.  ]\n",
      " [ 707000.  ]\n",
      " [ 472000.  ]\n",
      " [ 229999.97]\n",
      " [ 835000.  ]\n",
      " [1008000.  ]\n",
      " [2400000.  ]\n",
      " [ 639000.  ]\n",
      " [ 650000.  ]\n",
      " [ 600000.  ]\n",
      " [ 635000.  ]\n",
      " [1500000.  ]\n",
      " [ 887000.  ]\n",
      " [ 700000.  ]\n",
      " [ 450000.  ]\n",
      " [ 583975.  ]\n",
      " [ 850000.  ]\n",
      " [ 630000.  ]\n",
      " [ 649000.  ]\n",
      " [ 569000.  ]\n",
      " [ 520000.  ]\n",
      " [ 299999.97]\n",
      " [ 365000.  ]\n",
      " [ 856000.  ]\n",
      " [ 450000.  ]\n",
      " [ 680000.  ]\n",
      " [1080000.  ]\n",
      " [2679046.  ]\n",
      " [ 526000.  ]\n",
      " [1200000.  ]\n",
      " [1450000.  ]\n",
      " [ 450000.  ]\n",
      " [ 827321.  ]\n",
      " [ 422000.  ]\n",
      " [ 760000.  ]\n",
      " [ 880000.  ]\n",
      " [1100000.  ]\n",
      " [ 660000.  ]\n",
      " [ 309999.97]\n",
      " [ 991000.  ]\n",
      " [ 620000.  ]\n",
      " [ 842500.  ]\n",
      " [ 603000.  ]\n",
      " [ 505000.  ]\n",
      " [ 539000.  ]\n",
      " [ 710000.  ]\n",
      " [ 340000.  ]\n",
      " [ 638000.  ]\n",
      " [ 690000.  ]\n",
      " [ 875000.  ]\n",
      " [ 639300.  ]\n",
      " [1000000.  ]\n",
      " [ 832000.  ]\n",
      " [ 425000.  ]\n",
      " [ 308599.97]\n",
      " [ 400000.  ]\n",
      " [ 730000.  ]\n",
      " [ 550000.  ]\n",
      " [1350000.  ]\n",
      " [1200000.  ]\n",
      " [1350000.  ]\n",
      " [ 560000.  ]\n",
      " [ 565000.  ]\n",
      " [ 850000.  ]\n",
      " [ 527500.  ]\n",
      " [ 890000.  ]\n",
      " [ 344999.97]\n",
      " [ 434999.  ]\n",
      " [ 736000.  ]\n",
      " [ 465000.  ]\n",
      " [ 569900.  ]\n",
      " [ 400000.  ]\n",
      " [ 740000.  ]\n",
      " [1005000.  ]\n",
      " [ 447500.  ]\n",
      " [ 700000.  ]\n",
      " [ 322000.  ]\n",
      " [ 811000.  ]\n",
      " [ 330000.  ]\n",
      " [ 915000.  ]\n",
      " [ 505000.  ]\n",
      " [ 354999.97]\n",
      " [ 507000.  ]\n",
      " [ 331199.97]\n",
      " [ 682000.  ]\n",
      " [ 690000.  ]\n",
      " [2739630.  ]\n",
      " [ 765018.  ]\n",
      " [ 400000.  ]\n",
      " [ 608000.  ]\n",
      " [ 348000.  ]\n",
      " [ 562000.  ]\n",
      " [ 462000.  ]\n",
      " [ 597500.  ]\n",
      " [ 660000.  ]\n",
      " [ 552000.  ]\n",
      " [ 795000.  ]\n",
      " [ 768000.  ]\n",
      " [ 810000.  ]], shape=(600, 1), dtype=float32)\n",
      "Testing Accuracy: 75.83333333333333\n"
     ]
    }
   ],
   "source": [
    "pred = model(x_train)\n",
    "loss = loss_fn(y_train, pred)\n",
    "print(\"Training Accuracy:\", accuracy(pred, y_train, sigma, mu))\n",
    "\n",
    "pred = model(x_test)\n",
    "loss = loss_fn(y_test, pred)\n",
    "print(\"Testing Accuracy:\", accuracy(pred, y_test, sigma, mu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93887275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12692076  0.10856866  0.04461654 ... -0.07514493 -0.0744973\n",
      "   0.01260479]\n",
      " [-0.14683446 -0.14953981  0.18442567 ... -0.20339386  0.103581\n",
      "  -0.09291214]\n",
      " [ 0.1254563  -0.11002223 -0.05349731 ... -0.11784876 -0.03736782\n",
      "  -0.16272876]\n",
      " ...\n",
      " [-0.25042447  0.25035843  0.09431099 ...  0.13657267 -0.22676115\n",
      "   0.01360488]\n",
      " [-0.03390095  0.18360633  0.18887787 ...  0.04897064  0.2254355\n",
      "   0.05400588]\n",
      " [-0.15032893 -0.04964776 -0.18149091 ... -0.06873605 -0.10752581\n",
      "   0.31416753]]\n"
     ]
    }
   ],
   "source": [
    "weights, bias = model.layers[0].get_weights()\n",
    "print(weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
