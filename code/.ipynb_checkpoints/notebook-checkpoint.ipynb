{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "78e19fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4bb11327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107899\n",
      "55283\n",
      "52499\n",
      "26807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p6/bmvt9pvd0vd5t3yfr1yhfh580000gn/T/ipykernel_85846/911401261.py:2: DtypeWarning: Columns (13,20,53,54,59,60,61,62,63,64,65,66,67,68,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_housing_csv = pd.read_csv('../data/new_housing.csv')\n"
     ]
    }
   ],
   "source": [
    "housing_csv = pd.read_csv('../data/housing.csv')\n",
    "new_housing_csv = pd.read_csv('../data/new_housing.csv')\n",
    "\n",
    "#Length\n",
    "print(len(new_housing_csv))\n",
    "\n",
    "#Mask Sale Price\n",
    "mask = (new_housing_csv[\"SALE PRICE\"]) > 100000.0\n",
    "new_housing_csv_filtered = new_housing_csv[mask]\n",
    "\n",
    "#Length\n",
    "print(len(new_housing_csv_filtered))\n",
    "\n",
    "#Only important rows\n",
    "new_housing_csv_filtered = new_housing_csv_filtered[[\"LAND VAL\", \"PARCEL VAL\", \"IMPROVE VAL\", \"SALE PRICE\", \"SQFT\", \"ROOMS\", \"BEDROOM\", \"BATH\", \"LIVING AREA\", \"GROSS AREA\", \"YEAR\"]]\n",
    "\n",
    "\n",
    "#Remove Nulls\n",
    "mask = new_housing_csv_filtered.notnull().all(axis=1)\n",
    "new_housing_csv_filtered_second = new_housing_csv_filtered.loc[mask, :]\n",
    "print(len(new_housing_csv_filtered_second))\n",
    "\n",
    "#Remove 0s\n",
    "mask = (new_housing_csv_filtered_second != 0).all(axis=1)\n",
    "new_housing_csv_filtered_second = new_housing_csv_filtered_second.loc[mask, :]\n",
    "\n",
    "\n",
    "#Length\n",
    "print(len(new_housing_csv_filtered_second))\n",
    "\n",
    "\n",
    "housing_data = new_housing_csv_filtered_second[[\"LAND VAL\", \"PARCEL VAL\", \"SQFT\", \"ROOMS\", \"BEDROOM\", \"BATH\", \"LIVING AREA\", \"GROSS AREA\", \"YEAR\"]]\n",
    "housing_label = new_housing_csv_filtered_second[[\"SALE PRICE\"]]\n",
    "\n",
    "\n",
    "\n",
    "# print(new_housing_csv)\n",
    "\n",
    "# housing_data = housing_csv[[\"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"median_income\", \"population\", \"households\"]]\n",
    "# housing_label = housing_csv[[\"median_house_value\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4b3751dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_data\n",
    "Y = housing_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d2fc0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(X, axis=0)\n",
    "sigma = np.std(X, axis=0)\n",
    "X = (X - mu) / sigma\n",
    "\n",
    "mu = np.mean(Y, axis=0)\n",
    "sigma = np.std(Y, axis=0)\n",
    "Y = (Y - mu) / sigma\n",
    "\n",
    "X = pd.DataFrame.to_numpy(X)\n",
    "Y = pd.DataFrame.to_numpy(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7edc0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=128, activation='relu', input_shape=[5])\n",
    "        self.dense2 = tf.keras.layers.Dense(units=32, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=1, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1a6efb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "37f3bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26807\n"
     ]
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "y = tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "print(len(x))\n",
    "x_train = x[:20000]\n",
    "y_train = y[:20000]\n",
    "x_test = x[20001:26807]\n",
    "y_test = y[20001:26807]\n",
    "# Remove all instances where data is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0493b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.6543\n",
      "Epoch [200/1000], Loss: 0.6368\n",
      "Epoch [300/1000], Loss: 0.6260\n",
      "Epoch [400/1000], Loss: 0.6181\n",
      "Epoch [500/1000], Loss: 0.6120\n",
      "Epoch [600/1000], Loss: 0.6071\n",
      "Epoch [700/1000], Loss: 0.6028\n",
      "Epoch [800/1000], Loss: 0.5991\n",
      "Epoch [900/1000], Loss: 0.5960\n",
      "Epoch [1000/1000], Loss: 0.5934\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x_train)\n",
    "        loss = loss_fn(y_train, y_pred)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d4ada14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'linear_regression_7/dense_21/kernel:0' shape=(9, 128) dtype=float32, numpy=\n",
      "array([[-0.06697015,  0.15307553,  0.10536011, ..., -0.0234683 ,\n",
      "         0.02580248,  0.00414719],\n",
      "       [-0.0090399 , -0.20604908,  0.15159282, ..., -0.22253807,\n",
      "         0.1396048 , -0.04655507],\n",
      "       [ 0.07916412, -0.1490378 , -0.03775406, ..., -0.0596046 ,\n",
      "        -0.04012508, -0.14904018],\n",
      "       ...,\n",
      "       [-0.09475259,  0.05527806,  0.12234741, ..., -0.12555791,\n",
      "        -0.1590005 ,  0.0310942 ],\n",
      "       [-0.16864957, -0.13655506, -0.08860594, ..., -0.14906247,\n",
      "        -0.08730017,  0.18738829],\n",
      "       [-0.0215178 ,  0.17478403,  0.04087412, ...,  0.10312755,\n",
      "        -0.15654594,  0.07139026]], dtype=float32)>, <tf.Variable 'linear_regression_7/dense_21/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 0.01871272,  0.02407744, -0.00734727,  0.02027023, -0.0187937 ,\n",
      "        0.00764434,  0.00654991,  0.0043647 ,  0.01633397, -0.02579644,\n",
      "        0.00073665,  0.00724051,  0.02217017,  0.00572095,  0.03836054,\n",
      "       -0.00154527, -0.02584366, -0.01578968, -0.02133017, -0.01060119,\n",
      "        0.02377515,  0.00801332,  0.0123473 ,  0.00303752, -0.00188441,\n",
      "       -0.00838299, -0.03916801,  0.00315847,  0.01968961,  0.02179026,\n",
      "       -0.00072199, -0.04090243,  0.00691682,  0.00963828,  0.02320273,\n",
      "        0.01950666,  0.00473826, -0.01257804,  0.02635475, -0.00019705,\n",
      "        0.00647735, -0.0034017 , -0.0016155 ,  0.00035454, -0.00918334,\n",
      "       -0.00402555,  0.02112896, -0.0064391 , -0.00374942, -0.0105074 ,\n",
      "        0.03503921,  0.00476045, -0.00231157,  0.03655929,  0.00411633,\n",
      "        0.06411496,  0.00031282,  0.00805722, -0.00919977,  0.01161382,\n",
      "       -0.01495924,  0.01318346, -0.012017  ,  0.01714491,  0.00973667,\n",
      "       -0.00809664,  0.00218346, -0.01697056,  0.00186482,  0.01681297,\n",
      "        0.00539796, -0.00039307, -0.01821511, -0.00396083, -0.00031117,\n",
      "        0.01416481,  0.04393735,  0.0319437 ,  0.00288979,  0.02064991,\n",
      "        0.00091533, -0.01083893,  0.00103366, -0.00924283, -0.00532381,\n",
      "       -0.02031167,  0.02480723,  0.01507733,  0.05896486,  0.01461008,\n",
      "        0.01080589, -0.00192057,  0.02172114,  0.01753066,  0.0013625 ,\n",
      "        0.01604985,  0.01811775, -0.00790473,  0.0150902 ,  0.00393389,\n",
      "        0.00639222, -0.00440218,  0.00818095,  0.00339908,  0.00445309,\n",
      "        0.01056244,  0.01610912, -0.05491278,  0.01925235,  0.00044349,\n",
      "       -0.00733323,  0.00203769,  0.00905142,  0.00037437,  0.00209692,\n",
      "       -0.00910791, -0.0053025 , -0.02105139, -0.01317705,  0.02031164,\n",
      "       -0.00552335,  0.00790656, -0.03234601, -0.00983364,  0.01911201,\n",
      "       -0.00917096,  0.02041315,  0.01260538], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "85b15f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true, sigma, mu, threshold=2):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the predictions given the true labels, based on a threshold value.\n",
    "    \n",
    "    Parameters:\n",
    "    y_pred (np.ndarray): An array of predicted labels.\n",
    "    y_true (np.ndarray): An array of true labels.\n",
    "    threshold (float): The threshold value to use for measuring accuracy.\n",
    "    \n",
    "    Returns:\n",
    "    float: The accuracy of the predictions as a percentage.\n",
    "    \"\"\"\n",
    "    # Compute the absolute difference between predicted and true values\n",
    "    \n",
    "    mu = np.mean(Y, axis=0)\n",
    "    sigma = np.std(Y, axis=0)\n",
    "    Y = (Y - mu) / sigma\n",
    "    \n",
    "    y_pred = (y_pred * sigma) + mu\n",
    "    y_true = (y_true * sigma) + mu\n",
    "\n",
    "    diff = np.abs(y_pred - y_true)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = np.mean(diff <= threshold)\n",
    "    \n",
    "    # Convert to percentage\n",
    "    acc_pct = acc * 100\n",
    "    \n",
    "    return acc_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1b8fe4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(x_test)\n",
    "loss = loss_fn(y_test, pred)\n",
    "accuracy(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c4b4458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06697015  0.15307553  0.10536011 ... -0.0234683   0.02580248\n",
      "   0.00414719]\n",
      " [-0.0090399  -0.20604908  0.15159282 ... -0.22253807  0.1396048\n",
      "  -0.04655507]\n",
      " [ 0.07916412 -0.1490378  -0.03775406 ... -0.0596046  -0.04012508\n",
      "  -0.14904018]\n",
      " ...\n",
      " [-0.09475259  0.05527806  0.12234741 ... -0.12555791 -0.1590005\n",
      "   0.0310942 ]\n",
      " [-0.16864957 -0.13655506 -0.08860594 ... -0.14906247 -0.08730017\n",
      "   0.18738829]\n",
      " [-0.0215178   0.17478403  0.04087412 ...  0.10312755 -0.15654594\n",
      "   0.07139026]]\n"
     ]
    }
   ],
   "source": [
    "weights, bias = model.layers[0].get_weights()\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5791c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
